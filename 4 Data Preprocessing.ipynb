{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing using TFX\n",
    "\n",
    "In almost all the cases of Machine learning applications we need to transform our data into a more meaningful format. To help us in achieving tasks related to data processing TFX provides a component named `Tensorflow Transform`. It allows us to build transformation steps as tensorflow graphs.\n",
    "\n",
    "One of the major concerns we have in a production ml system is training/serving data skew. To help in these cases TFT builds are preprocessing graph to process daa and preserve it with determined boundary values for the feautes. Then this graph can be used in the inference phase of the model which ensures the same preprocessing for that data as well.\n",
    "\n",
    "In order to achieve that, we can combine the model along with the preprocessing graph along with the used parameters. Then that can be used in the API server. Also this gives us an additional benefit of being able to analyze the inference input data. One example is identifying `out of vocabulary word` inputs to a NLP model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing with TFT\n",
    "\n",
    "TFT processes the data we ingested to our pipeline with the earlier generated data schema and outputs 2 artifacts.\n",
    "\n",
    "1. Preprocessed training and evaluation datasets in TFRecord format.\n",
    "2. Exported preprocessing graph which we can use when we export our ml model.\n",
    "\n",
    "TFT provides a function named `preprocessing_fn` which will receive the raw data, apply the transformation and then return the processed data. Point to note is that all the transformation applied to the data should be tensorflow operations. This allows tft to distribute processing effectively dusing execution.\n",
    "\n",
    "<center>\n",
    "\n",
    "`pip install tensorflow-transform`\n",
    "</center>\n",
    "\n",
    "\n",
    "Once we have the package ready we can define the transoformations as we need using the preprocessing_fn like we said earlier. Example usage of preprocessing function is like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_transform as tft\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(inputs):\n",
    "\n",
    "    x = inputs['x']\n",
    "    x_normalized = tft.scale_to_0_1(x)\n",
    "    return { 'x_xf': x_normalized }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type functions will receive batch inputs as python dictionaries with key being the feature name and values being the raw data. It is expected to return transformed features as a dictionary as well.\n",
    "\n",
    "Some other important points about tft preprocessing are below.\n",
    "\n",
    "- **Feature naming**: As these features will get used by the components down the pipeline it is important to keep track of the naming of the transformed features.\n",
    "\n",
    "- **Data types**: it is important to cast the data to proper data types after transformations. (string, int32/64, float32/64)\n",
    "\n",
    "- **Preprocessing happens as batches**: We need to keep in mind this when applying transformations.\n",
    "\n",
    "- **No eager execution**: Which means we can only use tf graph operations.\n",
    "\n",
    "Since most of the operations need to run as tf graph operations, tft provides considerable amount of transformations we can use for a typical ML work task. Below are some examples.\n",
    "\n",
    "* tft.scale_to_z_score: Normalize feature to 0 mean and 1 std.\n",
    "\n",
    "* tft.buckeize: separate features into bins\n",
    "\n",
    "* tft.pca: To get the principal components of the feature\n",
    "\n",
    "* tft.compute_and_apply_vocabulary: Computes unique items in a feature column and assign indexed numerical form.\n",
    "\n",
    "Below are some NLP specific functions.\n",
    "\n",
    "* tft.ngram: Calculates the n-gram of given string data\n",
    "\n",
    "* tft.bag_of_words: Calculates the bag of words.\n",
    "\n",
    "* tft.tfidf: Calculates TFIDF of string data.\n",
    "\n",
    "Also [Tensorflow Text](https://github.com/tensorflow/text#installation) package provides more support for text processing including text normalization/ tokenization and language models like BERT.\n",
    "\n",
    "For computer vision related problems tft provides many options via tf.images and tf.io modules to image decoding, resize, adjusting, converting etc.\n",
    "\n",
    "Below is an example of reading tfrecord encoded image and preprocessing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_fn(raw_images):\n",
    "\n",
    "    raw_image_flatten = tf.reshape(raw_images, [-1])\n",
    "    img_rgb = tf.io.decode_jpeg(raw_image_flatten, channels=3)\n",
    "    img_gray = tf.image.rgb_to_grayscale(img_rgb)\n",
    "\n",
    "    img = tf.image.convert_image_dtype(img_gray, tf.float32)\n",
    "    resized_img = tf.image.resize_with_pad(img, target_height=300, target_width=300)\n",
    "\n",
    "    return tf.reshape(resized_img, [-1, 300, 300, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution of preprocessing function can be done in 2 methods. One is using tft as a standalone package or in a tfx pipeline.\n",
    "\n",
    "The below is a sample standalone execution usage of tft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata, schema_utils\n",
    "\n",
    "raw_data = [\n",
    "            {'x': 1.20},\n",
    "            {'x': 2.99},\n",
    "            {'x': 100.00},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to define metadata for the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "    schema_utils.schema_from_feature_spec({\n",
    "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
    "    }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now since we have the data and meta data we can execute it. To do that we can use tft provided bindings for apache beam based execution with AnalyzeAndTransform function. This function performs a 2 step process, first analyze the dataset with metadata and calculate necessary values and then transform. We can define other configs like batch size as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scripts/tft_transform_standalone.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scripts/tft_transform_standalone.py\n",
    "\n",
    "import tempfile\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata, schema_utils\n",
    "\n",
    "raw_data = [\n",
    "            {'x': 1.20},\n",
    "            {'x': 2.99},\n",
    "            {'x': 4.00},\n",
    "            ]\n",
    "\n",
    "raw_data_metadata = dataset_metadata.DatasetMetadata(\n",
    "    schema_utils.schema_from_feature_spec({\n",
    "        'x': tf.io.FixedLenFeature([], tf.float32),\n",
    "    }))\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "    x = inputs['x']\n",
    "    x_normalized = tft.scale_to_0_1(x)\n",
    "\n",
    "    return { 'x_xf': x_normalized }\n",
    "\n",
    "with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "    transformed_dataset, transform_fn = (  \n",
    "        (raw_data, raw_data_metadata) | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "\n",
    "transformed_data, transformed_metadata = transformed_dataset\n",
    "pprint.pprint(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason tft_beam does not work with jupyter notebook(I could not find out why!). So I have executed it in a python file. More details about this usage can be obtained from the [documentation](https://www.tensorflow.org/tfx/tutorials/transform/simple).\n",
    "\n",
    "But instead of wanting to run transformation as a standalone function, we can integrate it to ML pipelines. This is not complex as we only need to define the preprocessing_fn with the necessary transformations. But we need to keep track of transformations with proper structures(remember outputs should be dictionary with key being feature name and values being the transformed data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Machine_Learning_Pipelines-cCuFzokH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d8130ec584c6fad87bda1a68cc74a67224bab37bcf74941c3cce44e422d7e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
