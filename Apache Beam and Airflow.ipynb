{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Beam and Airflow for Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been looking at building ML pipeline componets separately and how they would interconnect. Now we should look at how we can put all those components together and how to run a full pipeline. To do that we will mainly look at 2 orchestors Apache Airflow and Beam.\n",
    "\n",
    "The importance of this type of orchestration tool is that otherwise we would need to write code to check when a component complete its task and trigger the other etc. (earlier we used interactive pipelines, but we cant use those in production systems.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Beam\n",
    "\n",
    "TFX comes with a beam version by default. Therefore for a minimal setup using beam as orchastration tool is a valid choice. It is straight forward to setup and use while allowing to use existing data processing pipelines like google cloud dataflow.\n",
    "But it lacks tools for scheduling model updates or monitoring the pipeline job progresses.\n",
    "\n",
    "\n",
    "### Apache Airflow\n",
    "\n",
    "Apache Airflow is already a widely used tool for data-loading task. It provide support to connect with production ready databases like PostgreSQL and execute partial pipelines etc which can save significant amount of time.\n",
    "\n",
    "\n",
    "### Kubeflow pipelines\n",
    "\n",
    "If there's an already existing kubernetes pipeline then it would make sense to use a Kubeflow pipelines tool. But it is complicated to setup compared to other tools. On the other hand it opens up opportunities to view TFDV and TFMA visializations, model lineage and artifact collections.\n",
    "\n",
    "\n",
    "With those details in mind, we can now look in to converting our interactive code to a script which can be used to automate the whole process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Machine_Learning_Pipelines-cCuFzokH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d8130ec584c6fad87bda1a68cc74a67224bab37bcf74941c3cce44e422d7e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
